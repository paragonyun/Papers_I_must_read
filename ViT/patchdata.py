import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import numpy as np
import torch

class PatchGenerator:
    """Patchë¥¼ ë§Œë“œëŠ” ê³³ì…ë‹ˆë‹¤.
    torch.unfoldë¥¼ ì´ìš©í•˜ë©° ì›ë³¸ ì´ë¯¸ì§€ë¥¼ patch_sizeì— ë§ê²Œ ìë¦…ë‹ˆë‹¤.
    """

    def __init__(self, patch_size):
        self.patch_size = patch_size

    def __call__(self, img):
        num_channels = img.size(0) # (c, w, h)

        # wë°©í–¥ìœ¼ë¡œ ë¨¼ì € ìë¥¸ë‹¤ìŒ, hë°©í–¥ìœ¼ë¡œ ì˜ë¼ì¤ë‹ˆë‹¤.
        # unfoldë¥¼ ë‘ë²ˆ ê±°ì¹˜ê²Œ ë˜ë©´ (3 x w/p x h/p x p x p)ê°€ ë‚˜ì˜µë‹ˆë‹¤.
        # ì´ë“¤ì„ 3 x wh/p^2 x p x p í˜•íƒœë¡œ ë°”ê¿”ì£¼ê¸° ìœ„í•´ reshapeì„ í™œìš©í•©ë‹ˆë‹¤.
        patches = img.unfold(1, self.patch_size, self.patch_size).\
                    unfold(2, self.patch_size, self.patch_size).\
                    reshape(num_channels, -1, self.patch_size, self.patch_size)
        
        # permuteë¥¼ ì´ìš©í•´ patchì˜ ê°¯ìˆ˜ì¸ wh/p^2ì„ ë§¨ ì•ìœ¼ë¡œ ë¹¼ì¤ë‹ˆë‹¤.
        patches = patches.permute(1, 0, 2, 3)
        num_patch = patches.size(0)

        return patches.reshape(num_patch, -1)


class Flattened2Dpaches:
    def __init__(self, patch_size=16, img_size=256, batch_size=64):
        self.patch_size = patch_size
        self.img_size = img_size
        self.batch_size = batch_size

    def make_weight(self, labels, nclasses):
        """classìˆ˜ê°€ ë‹¬ë¼ë„ samplingë˜ëŠ” classë¥¼ ë™ì¼í•˜ê²Œ ê°€ì ¸ê°€ê¸° ìœ„í•œ 
        weightë¥¼ ì„¤ì •í•˜ëŠ” ê³³ì…ë‹ˆë‹¤.
        ex) https://www.maskaravivek.com/post/pytorch-weighted-random-sampler/
        ì‰½ê²Œ ë§í•´, ë°ì´í„°ë¥¼ sampling í•  ë•Œ ê· í˜•ìˆê²Œ samplingí•˜ê¸° ìœ„í•œ weightë¥¼ ë§Œë“œëŠ” ê³³ì…ë‹ˆë‹¤.
        """
        labels = np.array(labels)
        weight_arr = np.zeros_like(labels) # labels ë§Œí¼ ë¹ˆ ë°°ì—´ì„ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤.
        _, counts = np.unique(labels, return_counts=True) # ê° class ë³„ë¡œ ëª‡ ê°œì˜ valueê°€ ìˆëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        for cls in range(nclasses):
            weight_arr = np.where(labels == cls, 1/counts[cls], weight_arr) # np.whereë¡œ ì¡°ê±´ì— ë§ëŠ” indexë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤. np.where(ì¡°ê±´, Trueì¼ ë•Œ, False ì¼ë•Œ)

        return weight_arr

    def patchedata(self):
        """patchë¥¼ ë§Œë“¤ì–´ dataloaderë¥¼ return í•©ë‹ˆë‹¤."""
        mean = (0.4914, 0.4822, 0.4465)
        std = (0.2023, 0.1994, 0.2010)

        train_transform = transforms.Compose([
            transforms.Resize(self.img_size),
            transforms.RandomCrop(self.img_size, padding=2), # paddingìœ¼ë¡œ cropì„ í•´ë„ ì›ë³¸ ì‚¬ì´ì¦ˆê°€ ìœ ì§€ë˜ë„ë¡ í•©ë‹ˆë‹¤.
            transforms.RandomHorizontalFlip(),
            transforms.ToTensor(),
            transforms.Nomalize(mean, std),
            PatchGenerator(self.patch_size)
        ])

        test_transform = transforms.Compose([
            transforms.Resize(self.img_size),
            transforms.ToTensor(),
            transforms.Normalize(mean, std),
            PatchGenerator(self.patch_size)
        ])

        trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transform)
        testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transform)

        # testsetì—ì„œ valsetì„ ê±¸ëŸ¬ì£¼ê¸° ìœ„í•œ index í˜•ì„±ì…ë‹ˆë‹¤.
        evens = list(range(0, len(testset), 2))
        odds = list(range(1, len(testset), 2))

        # ì§ìˆ˜ë§Œ valsetìœ¼ë¡œ ì”ë‹ˆë‹¤.
        valset = torch.utils.data.Subset(testset, evens)
        testset = torch.utils.data.Subset(testset, odds)

        weights = self.make_weight(trainset.targets, len(trainset.classes)) # Weight Samplingì„ ìœ„í•œ Weight Arrayë¥¼ ë§Œë“­ë‹ˆë‹¤.
        weights = torch.DoubleTensor(weights) # Tensorë¡œ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤.
        sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights)) # ê°€ì¤‘ì¹˜ê°€ ì ìš©ëœ sampler ìƒì„±
        
        trainloader = DataLoader(trainset, batch_size=self.batch_size, sampler=sampler)
        valloader = DataLoader(valset, batch_size=self.batch_size, sampler=sampler)
        testloader = DataLoader(testset, batch_size=self.batch_size, sampler=sampler)

        return trainloader, valloader, testloader

def imshow(img):
    """ì‹œê°í™”ë¥¼ ìœ„í•œ í•¨ìˆ˜ì…ë‹ˆë‹¤."""
    plt.figure(figsize=(100, 100))
    plt.imshow(img.permute(1,2,0).numpy())
    plt.savefig("./patch.png")
    plt.show()

if __name__ == "__main__":
    """ì´ê±°ë§Œ ë‹¨ë…ìœ¼ë¡œ ì‹¤í–‰ ì‹œì¼°ì„ ë•Œ ì˜ ë™ì‘í•˜ë‚˜ í…ŒìŠ¤íŠ¸ í•´ë³´ê¸° ìœ„í•¨ì…ë‹ˆë‹¤."""
    print("ğŸ‘€ ì˜ ë˜ë‚˜ í•¨ ë³´ê² ìŠµë‹ˆë‹¤...")
    batch_size = 64
    patch_size = 8
    img_size = 32
    num_patches =int((img_size*img_size) / (patch_size*patch_size))

    patch_cls = Flattened2Dpaches(img_size=img_size, patch_size=patch_size, batch_size=batch_size)
    train_loader, _ , _ = patch_cls.patchedata()
    
    imgs, labels = next(iter(train_loader))
    print(imgs.size(), labels.size())

    ## í•˜ë‚˜ë§Œ êº¼ë‚´ì™€ì„œ í™•ì¸, flattenëë˜ ê±¸ ë‹¤ì‹œ ì‚¬ê°í˜•ìœ¼ë¡œ ë§Œë“¤ì–´ì•¼ í•˜ê¸° ë•Œë¬¸ì— ë‹¤ì‹œ reshapeìœ¼ë¡œ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤.
    sample = imgs.reshape(batch_size, num_patches, -1, patch_size, patch_size)[0]

    imshow(torchvision.utils.make_grid(sample, nrow=int(img_size/patch_size)))